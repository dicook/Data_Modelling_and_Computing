---
title: "ETC 1010 Assignment 4"
author: "Di Cook"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  collapse = TRUE,
  comment = "",
  fig.height = 8,
  fig.width = 12,
  fig.align = "center",
  cache = FALSE
)
```

# Instructions

- This is a team assignment. 
- You need to write a report with answers to each of the questions. 
- Turn in the `html` output file, and also the `Rmd` file. 
- Total points for the assignment is 20. Five points of the score from the assignment will be given by another team, who will give you full marks if they can compile your report, and get the same answers as you, and find your explanations of the plots understandable and informative. Five points will be for individual effort. And the remaining 10 points will be the final group report.

# Exercise

*[Melbourne property prices have taken their biggest hit since 2012, falling by almost 2 per cent in the past three months](https://www.domain.com.au/news/melbourne-median-house-price-falls-to-882082-over-june-quarter-domain-group-report-20180726-h134ao-754199/)* Jim Malo, Jul 26 2018, Domain

This assignment explores the data provided on [Melbourne house prices by Anthony Pino](https://www.kaggle.com/anthonypino/melbourne-housing-market). The goal is to examine whether housing prices have cooled in Melbourne, and help Anthony decide whether it is time to buy a two bedroom apartment in Northcote. 

## Your tasks

1. Make a map of Melbourne showing the locations of the properties. 

```{r echo=FALSE, eval=FALSE}
library(tidyverse)
library(lubridate)
mh <- read_csv("data/Melbourne_housing_FULL.csv") %>%
  ???(lon=Longtitude, lat=Lattitude) %>%
  mutate(Date = ???(Date))
library(ggmap)
map <- get_map(location = ???, zoom=???)
ggmap(map) + geom_point(data=mh, aes(x=???, y=???), colour=???, size=???, alpha=???)
```

2. Here we are going to examine the prices of 2 bedroom flats in Northcote. 
    a. Filter the data to focus only on the records for Northcote units. Make a plot of Price by Date, facetted by number of bedrooms. The main thing to learn from this plot is that there are many missing values for number of bedrooms.
    b. Impute the missing values, based on the regression method (covered in class). Make sure your predicted value is an integer. Re-make the plot of Price by Date, facetted by number of bedrooms. 
    c. Write a description of what you learn from the plot, particularly about the trend of 2 bedroom unit prices in Northcote.

```{r echo=FALSE, eval=FALSE}
nc <- mh %>% filter(??? == ???, ??? == ???)
ggplot(nc, aes(x=???, y=???)) + 
  geom_???() + geom_???(se=F) +
  facet_wrap(~???, ncol=4) 
library(???)
nc_ms <- nc %>% bind_shadow()
br2 <- ???(Bedroom2~???, data=nc_ms)
nc_ms <- nc_ms %>%
  ???(Bedroom2=ifelse(is.na(???),
    round(predict(br2, new=nc_ms), ???), ???))
ggplot(nc_ms, aes(x=???, y=???)) + 
  geom_???() + geom_???(se=F) +
  facet_wrap(~???, ncol=4) 
```

3. Focusing on 2 bedroom units, we are going to explore the trend in prices for each suburb.  
    a. You will need to impute the Bedroom2 variable, in the same way done in the previous question. 
    b. Fit a linear model to each suburb (many models approach). Collect the model estimates, and also the model fit statistics. Make a plot of intercept vs slope. Using plotly what suburb has had the largest increase, which has had the biggest decrease in prices?
    c. Summarise the $R^2$ for the model fits for all the suburbs. Which suburbs have the worst fitting models?  Plot the Price vs Date of the best fitting model. Is the best fitting model a good fit?
    d. Write a paragraph on what you have learned about the trend in property prices across Melbourne.

```{r echo=FALSE, eval=FALSE}
# Remove the Suburbs where there is little data
mh_ms %>% filter(Type == ???, Bedroom2 == ???) %>% count(???, sort = TRUE) %>% ggplot(aes(x=n)) + geom_histogram()
keep <- mh_ms %>% filter(Type == ???, Bedroom2 == ???) %>% 
  count(???, sort = TRUE) %>%
  filter(??? > 30)
mh_u <- mh_ms %>% filter(Suburb %in% ???) %>%
  mutate(days = as.numeric(??? - ymd("2016-01-28")))
library(purrr)
by_suburb <- mh_u %>% 
  select(???, ???, ???, ???) %>%
  group_by(???) %>% 
  nest()
by_suburb <- by_suburb %>% 
  mutate(
    model = purrr::map(data, ~ lm(??? ~ ???, 
                                  data = .))
  )
suburb_coefs <- by_suburb %>% 
  unnest(model %>% purrr::map(broom::???))
suburb_coefs <- suburb_coefs %>% 
  select(???, ???, ???) %>% 
  spread(term, estimate) %>%
  rename(intercept = `(Intercept)`)
head(suburb_coefs)
p <- ggplot(suburb_coefs, aes(x=???, y=???, 
                          label=???)) +
  geom_point(alpha=0.5, size=2) 
library(plotly)
ggplotly(???)
suburb_fit <- by_suburb %>% 
  unnest(model %>% 
           purrr::map(broom::???))
ggplot(suburb_fit, aes(x=???)) + geom_???()
bestfit <- suburb_fit %>% filter(??? > 0.08)
mh_u_sub <- mh_u %>% filter(Suburb %in% ???)
ggplot(data=mh_u_sub, aes(x=???, y=???)) + 
         geom_???() + geom_???(method="lm", se=FALSE)
worstfit <- suburb_fit %>% filter(r.squared < 0.001)
```

4. Still focusing on apartments (units) examine the results of the auctions, with the Method variable, across suburbs. This variable contains results of the auction, whether the property sold, or not. It may be that in recent months there is a higher proportion of properties that didn't sell. This would put downward pressure on prices. 
    a. Compute the counts of the levels of Method, ignoring the suburbs. 
    b. The categories PI (passed in) and VB (vendor bid) indicate the property did not sell. Compute the proportion of properties in these two categories for each suburb, for each month since 2016. 
    c. Plot the proportions against year/month (make a new variable time is an integer with 1 being the first month of the data in 2016 and each month since then increments time by 1).  Add a smoother to show the trend in these proportions. Does it look like there is an increase in units that aren't selling?
    d. Explain why the data was aggregated to month before computing the proportions. 

```{r echo=FALSE, eval=FALSE}
mh_u %>% count(???, sort=TRUE)
mh_u_mth <- mh_u %>% 
  mutate(year = year(???), month = month(???)) %>%
  group_by(???, ???, ???) %>%
  count(???) %>%
  mutate(p = ???/sum(n)) %>%
  filter(Method %in% c(???, ???)) %>%
  mutate(time = (???-2016)*???+???)
ggplot(mh_u_mth, aes(x=???, y=p, label=???)) + 
  geom_???() +
  geom_???() + 
  facet_wrap(~???)
ggplotly()
```

5. Fit the best model for Price that you can, for houses around Monash University.
    a. Impute the missing values for Bathroom (similarly to Bedroom2).
    b. Subset the data to these suburbs "Notting Hill", "Glen Waverley",
         "Clayton", "Clayton South","Oakleigh East", "Huntingdale", 
         "Mount Waverley".
    c. Make a scatterplot of Price vs Date by Bedroom2 and Bathroom, with a linear model overlaid. What do you notice? There are only some combinations of bedrooms and bathrooms that are common. Subset your data to houses with 3-4 bedrooms and 1-2 bathrooms. 
    d. Using date, rooms, bedroom, bathroom, car and landsize build your best model for price. There are some missing values on Car and Landsize, which may be important to impute. Think about interactions as well as main effects. (There are too many missing values to use BuildingArea and YearBuilt. The other variables in the data don't make sense to use.)
    
```{r echo=FALSE, eval=FALSE}
monash <- mh_ms %>% filter(Suburb %in% c(???, ???,
         ???, ???,???, ???, 
         ???), 
                       Type == ???) %>%
  select(???, ???,???, ???, ???, ???,???, ???) %>%
  mutate(day=as.numeric(???)) %>%
  mutate(day=day-min(???))
monash <- monash %>% filter(Bedroom2 > ???, Bedroom2 < ???, Bathroom < ???) 
ggplot(monash, aes(x=???, y=???)) + 
  geom_???() + 
  geom_???(method="lm", se=FALSE) + 
  facet_grid(???~???)
library(broom)
monash_fit <- lm(Price~???, data=monash)
???(monash_fit)
???(monash_fit)
```

# Grading

Points for the assignment will be based on:

- Accuracy of your answers to the given questions. 
- How well you have conducted the analysis, and written your answers. 
- Whether the Rmd file, can take data file as provided, produce the tidy data, and plots reported in your final submission.
- How well you have worked with your group members on completing this work. Your score for the group component will be adjusted by the amount of effort your team mates independently and anonymously report. 
